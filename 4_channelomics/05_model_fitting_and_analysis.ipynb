{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import theano.tensor as tt\n",
    "import time\n",
    "\n",
    "from delfi.neuralnet.NeuralNet import NeuralNet\n",
    "from delfi.neuralnet.Trainer import Trainer\n",
    "\n",
    "import sys; sys.path.append('../')\n",
    "from common import col, svg, plot_pdf\n",
    "\n",
    "from model.ChannelOmni import ChannelOmni\n",
    "from model.ChannelOmniStats import ChannelOmniStats as ChannelStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "stats = []\n",
    "for root, dirs, files in os.walk(\"./data/\", topdown=False):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        if filename[-len('theta.npy'):] == 'theta.npy':\n",
    "            params += [np.load(filename)]\n",
    "        if filename[-len('stats.npy'):] == 'stats.npy':\n",
    "            stats += [np.load(filename)] \n",
    "\n",
    "params = np.asarray(params).reshape(-1, 8)\n",
    "stats = np.asarray(stats).reshape(-1, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_lims= np.array([\n",
    "    [0, 1],\n",
    "    [-10., 10.],\n",
    "    [-120., 120.],\n",
    "    [0., 2000],\n",
    "    [0., 0.5],\n",
    "    [0, 0.05],\n",
    "    [0., 0.5],\n",
    "    [0, 0.05]\n",
    "])\n",
    "\n",
    "m = ChannelOmni(third_exp_model=False)\n",
    "p = dd.Uniform(lower=prior_lims[:,0], upper=prior_lims[:,1])\n",
    "s = ChannelStats()\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "res = infer.APT(\n",
    "    g,\n",
    "    pilot_samples=(params, stats), \n",
    "    n_hiddens=[250,250],\n",
    "    seed=101, \n",
    "    n_mades=5,\n",
    "    prior_norm=True,\n",
    "    impute_missing=False,\n",
    "    density='maf', \n",
    "    obs=stats[0,:],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log, train_data, posterior = res.run(\n",
    "    n_train=params.shape[0], \n",
    "    n_rounds=1, \n",
    "    minibatch=100,\n",
    "    epochs=1000,\n",
    "    silent_fail=False,\n",
    "    proposal='mog',\n",
    "    val_frac=0.05,\n",
    "    patience=30,\n",
    "    monitor_every=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p results/net_maf\n",
    "pickle.dump(res.network, open('results/net_maf/net.pkl', 'wb'))\n",
    "pickle.dump(res, open('results/net_maf/res.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot mode samples and calculate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys; sys.path.append('../')\n",
    "\n",
    "from box import Box\n",
    "from common import plot_pdf, samples_nd, col, svg\n",
    "from support_files.pickle_macos import pickle_load\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# support\n",
    "dats = pickle.load(open('support_files/manualfit_params.pkl', 'rb'))  # curve fit values\n",
    "mats = Box(pickle_load('support_files/pow1_mats_comp.pkl'))\n",
    "\n",
    "# model\n",
    "protocols = ['ap', 'act', 'inact', 'deact', 'ramp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode sample\n",
    "import cma\n",
    "\n",
    "prior_lims = np.vstack((p.lower, p.upper)).T\n",
    "\n",
    "def mode_sample(posterior_, init=(prior_lims[:,1] + prior_lims[:,0])/2, rate=0.01):\n",
    "    es = cma.CMAEvolutionStrategy(\n",
    "        init,\n",
    "        rate,\n",
    "        {'scaling_of_variables':(prior_lims[:,1]-prior_lims[:,0]),\n",
    "         'bounds': [list(prior_lims[:,0]), list(prior_lims[:,1])]\n",
    "        })\n",
    "    es.optimize(lambda x: -1. * posterior_.eval(x) )\n",
    "    es.result_pretty()\n",
    "    return es.best.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "errs = []\n",
    "sams = 1\n",
    "\n",
    "N_chans = mats['ap']['data'].shape[0]\n",
    "\n",
    "idxs = []\n",
    "ccs = []\n",
    "l2s = []\n",
    "\n",
    "for idx_chan in tqdm(range(N_chans)):\n",
    "    try:\n",
    "        name_gt = mats['ap']['names'][idx_chan]\n",
    "\n",
    "        trace_gt = {\n",
    "            'v_act':   {'data' : mats['act']['data'][idx_chan,   6:, 1:].T},\n",
    "            'v_inact': {'data' : mats['inact']['data'][idx_chan, 6:, 1:].T},\n",
    "            'v_deact': {'data' : mats['deact']['data'][idx_chan, 6:, 1:].T},\n",
    "            'v_ap':    {'data' : mats['ap']['data'][idx_chan,    6:, 1:].T},\n",
    "            'v_ramp':  {'data' : mats['ramp']['data'][idx_chan,  6:, 1:].T},\n",
    "        }\n",
    "\n",
    "        stats_gt = s.calc([trace_gt])\n",
    "\n",
    "        stats_gt_norm = stats_gt\n",
    "        posterior_normed_gt = res.predict(stats_gt_norm.astype(np.float32))\n",
    "\n",
    "        samx = mode_sample(posterior_normed_gt).reshape(1,-1)\n",
    "\n",
    "        params_sam = np.asarray(samx).reshape(-1)\n",
    "        trace_sam = m.gen_single(params_sam)\n",
    "        stats_sam = s.calc([trace_sam])\n",
    "\n",
    "        # concat'ed timeseries\n",
    "        trace_sam_concat = np.concatenate((\n",
    "            trace_sam['v_act']['data'].reshape(-1),\n",
    "            trace_sam['v_inact']['data'].reshape(-1),\n",
    "            trace_sam['v_deact']['data'].reshape(-1),\n",
    "            trace_sam['v_ap']['data'].reshape(-1),\n",
    "            trace_sam['v_ramp']['data'].reshape(-1)\n",
    "        ))\n",
    "        trace_gt_concat = np.concatenate((\n",
    "            trace_gt['v_act']['data'].reshape(-1),\n",
    "            trace_gt['v_inact']['data'].reshape(-1),\n",
    "            trace_gt['v_deact']['data'].reshape(-1),\n",
    "            trace_gt['v_ap']['data'].reshape(-1),\n",
    "            trace_gt['v_ramp']['data'].reshape(-1)\n",
    "        ))\n",
    "\n",
    "        # calculate corrcoef\n",
    "        corrcoef = np.corrcoef(trace_sam_concat, trace_gt_concat)[0,1]\n",
    "        ccs.append(corrcoef)\n",
    "\n",
    "        l2 = np.linalg.norm(stats_gt-stats_sam)\n",
    "        l2s.append(l2)\n",
    "\n",
    "        idxs.append(idx_chan)\n",
    "\n",
    "\n",
    "        protocols = ['ap', 'act', 'inact', 'deact', 'ramp']\n",
    "\n",
    "        with mpl.rc_context(fname='../.matplotlibrc'):\n",
    "            f = 0.6\n",
    "            plt.figure(figsize=(f*20/2.54, f*5/2.54))\n",
    "\n",
    "            for p, protocol in enumerate(protocols):\n",
    "                if protocol == 'ap':\n",
    "                    ds = 10\n",
    "                else:\n",
    "                    ds = 100\n",
    "\n",
    "                plt.subplot(2, 5, p+1)\n",
    "\n",
    "                if p == 0:\n",
    "                    plt.gca().set_title('Channel {} Â· cc={:.3f}'.format(name_gt, corrcoef),\n",
    "                                        loc='left', pad=15,\n",
    "                                        fontdict={'fontsize': 8})\n",
    "\n",
    "                N = trace_gt['v_' + protocol]['data'].shape[0]\n",
    "\n",
    "                if N == 1:\n",
    "                    cm = sns.light_palette(col['GT'], N, reverse=True)\n",
    "                    plt.gca().set_prop_cycle('color', cm)\n",
    "                else:\n",
    "                    cm = sns.light_palette(col['GT'], N)\n",
    "                    plt.gca().set_prop_cycle('color',cm)\n",
    "\n",
    "                plt.plot(trace_sam['v_' + protocol]['time'][::ds],\n",
    "                         trace_gt['v_' + protocol]['data'].T[::ds],\n",
    "                         linewidth=1.);  # usually 1.5\n",
    "\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "\n",
    "                sns.despine(left=True, bottom=True, offset=5)\n",
    "\n",
    "            for p, protocol in enumerate(protocols):\n",
    "                if protocol == 'ap':\n",
    "                    ds = 10\n",
    "                else:\n",
    "                    ds = 100\n",
    "\n",
    "                plt.subplot(2, 5, p+6)\n",
    "\n",
    "                N = trace_gt['v_' + protocol]['data'].shape[0]\n",
    "\n",
    "                if N == 1:\n",
    "                    cm = sns.light_palette(col['CONSISTENT1'], N, reverse=True)\n",
    "                    plt.gca().set_prop_cycle('color',cm)\n",
    "                else:\n",
    "                    cm = sns.light_palette(col['CONSISTENT1'], N)\n",
    "                    plt.gca().set_prop_cycle('color',cm)\n",
    "\n",
    "                plt.plot(trace_sam['v_' + protocol]['time'][::ds],\n",
    "                         trace_sam['v_' + protocol]['data'].T[::ds],\n",
    "                         linewidth=1., alpha=1.0);  # usually 1.5\n",
    "\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                sns.despine(left=True, bottom=True, offset=5)\n",
    "\n",
    "                plt.plot([0., 100.],[-0.1, -0.1], color='k', linewidth=2)\n",
    "                plt.text(0.0, -0.4, '100ms', fontsize=8)\n",
    "\n",
    "\n",
    "            import os\n",
    "\n",
    "            !mkdir -p results/net_maf\n",
    "            !mkdir -p results/net_maf/svg\n",
    "            \n",
    "            plt.savefig('./results/net_maf/svg/{}.svg'.format(idx_chan))\n",
    "            plt.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ccs, open('./results/net_maf/ccs.pkl', 'wb'))\n",
    "pickle.dump(l2s, open('results/net_maf/l2s.pkl', 'wb'))\n",
    "pickle.dump(idxs, open('results/net_maf/idxs.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
