{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to identify start and end point\n",
    "This notebook finds parameter sets that are far apart in parameter space but produce similar activity.  \n",
    "This notebook is somewhat based on visual inspection (similarity of traces).\n",
    "\n",
    "Eventually, it produces 8 pairs of parameter sets. We used the forth one (starting from index 0, it is -> 3). This parameter set is saved in results/31D_pairs/similar_and_good/sample_pair_3.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import delfi.distribution as dd\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "sys.path.append(\"model/setup\")\n",
    "sys.path.append(\"model/simulator\")\n",
    "sys.path.append(\"model/inference\")\n",
    "sys.path.append(\"model/visualization\")\n",
    "sys.path.append(\"model/utils\")\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import netio\n",
    "import viz\n",
    "import importlib\n",
    "import viz_samples_start_end_point as viz_samples_thesis\n",
    "import train_utils as tu\n",
    "import startEndUtils as seu\n",
    "from find_pyloric import merge_samples, params_are_bounded\n",
    "import dill as pickle\n",
    "import matplotlib as mpl\n",
    "\n",
    "from common import col, svg, samples_nd\n",
    "\n",
    "PANEL_A = 'illustration/panel_a.svg'\n",
    "PANEL_B = 'svg/panel_b.svg'\n",
    "PANEL_C = 'svg/panel_c.svg'\n",
    "PANEL_D = 'svg/panel_d.svg'\n",
    "PANEL_E = 'svg/panel_e.svg'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = netio.load_setup(\"train_31D_R1_BigPaper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/31D_nets/191001_seed1_Exper11deg.pkl', 'rb') as file:\n",
    "    inf_SNPE_MAF, log, _ = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = netio.create_prior(params, log=True)\n",
    "dimensions = np.sum(params.use_membrane) + 7\n",
    "lims = np.asarray([-np.sqrt(3)*np.ones(dimensions), np.sqrt(3)*np.ones(dimensions)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = \"results/31D_samples/pyloricsamples_31D_noNaN_3.npz\"\n",
    "pilot_data, trn_data, params_mean, params_std = tu.load_trn_data_normalize(filedir, params)\n",
    "print('We use', len(trn_data[0]), 'training samples.')\n",
    "\n",
    "stats = pilot_data[1]\n",
    "stats_mean = np.mean(stats, axis=0)\n",
    "stats_std  = np.std(stats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = netio.create_prior(params, log=True)\n",
    "params_mean = prior.mean\n",
    "params_std = prior.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_pyloric import merge_samples, params_are_bounded\n",
    "\n",
    "labels_ = viz.get_labels(params)\n",
    "prior_normalized = dd.Uniform(-np.sqrt(3)*np.ones(dimensions), np.sqrt(3)*np.ones(dimensions), seed=params.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summstats_experimental = np.load('results/31D_experimental/190807_summstats_prep845_082_0044.npz')['summ_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_pyloric import merge_samples, params_are_bounded\n",
    "\n",
    "prior_normalized = dd.Uniform(-np.sqrt(3)*np.ones(dimensions), np.sqrt(3)*np.ones(dimensions), seed=params.seed)\n",
    "\n",
    "target = summstats_experimental\n",
    "posterior_MAF = inf_SNPE_MAF.predict([target]) # given the current sample, we now predict the posterior given our simulation outcome. Note that this could just be overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_MAF_11 = merge_samples(\"results/31D_samples/02_cond_vals\", name='conductance_params')\n",
    "samples_MAF_11 = np.reshape(samples_MAF_11, (1000*2520, 31))\n",
    "print(np.shape(samples_MAF_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create database of (theta, x)\n",
    "### Start points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "pyloric_sim = netio.create_simulators(params)\n",
    "summ_stats = netio.create_summstats(params)\n",
    "\n",
    "offsets = [50000,50000, 50000,50000, 50000,50000, 50000,50000, 50000,50000, 50000,50000]\n",
    "exp_stds =  np.asarray([279,  133, 113, 150, 109, 60,  169, 216,  0.040, 0.059, 0.054, 0.065, 0.034,  0.054, 0.060])\n",
    "print('stats_std', stats_std)\n",
    "exp_stds = stats_std\n",
    "\n",
    "indizes = range(25)\n",
    "\n",
    "all_zero5_params = []\n",
    "all_zero5_stats  = []\n",
    "all_one_params = []\n",
    "all_one_stats  = []\n",
    "\n",
    "counter = 0\n",
    "start_time = time.time()\n",
    "for ind in indizes:\n",
    "    if ind % 100 == 0: print('---- Index:', ind, '----')\n",
    "    target_params = samples_MAF[ind]\n",
    "    target = target_params\n",
    "    \n",
    "    if (target[24] > 2.1-np.sqrt(3) and target[24] < 2.5-np.sqrt(3)) and (target[25] > 0.35-np.sqrt(3) and target[25] < 0.75-np.sqrt(3)):\n",
    "        target_params = target_params * params_std + params_mean\n",
    "        out_target = pyloric_sim[0].gen_single(deepcopy(target_params), seed_sim=True, to_seed=1) # params.true_params gives the synaptic strengths #  165000\n",
    "        ss = summ_stats.calc([out_target])[0]\n",
    "        ss_diff = np.abs(summstats_experimental[:15] - ss[:15]) / exp_stds[:15]\n",
    "        if np.all(ss_diff < 0.1):\n",
    "            all_one_params.append(target_params)\n",
    "            all_one_stats.append(ss)\n",
    "            print('Found 0.1 std diff')\n",
    "\n",
    "np.savez('../results/pairs/31D_paper/all_similar_to_obs/sample_params_start.npz', params=all_one_params, summ_stats=all_one_stats)\n",
    "print('Overall time:  ', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from copy import deepcopy\n",
    "importlib.reload(mpl); importlib.reload(plt); importlib.reload(sns)\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "pyloric_sim = netio.create_simulators(params)\n",
    "summ_stats = netio.create_summstats(params)\n",
    "\n",
    "offsets = [50000,50000, 50000,50000, 50000,50000, 50000,50000, 50000,50000, 50000,50000]\n",
    "exp_stds =  np.asarray([279,  133, 113, 150, 109, 60,  169, 216,  0.040, 0.059, 0.054, 0.065, 0.034,  0.054, 0.060])\n",
    "print('stats_std', stats_std)\n",
    "exp_stds = stats_std\n",
    "\n",
    "indizes = range(50)\n",
    "\n",
    "all_zero5_params = []\n",
    "all_zero5_stats  = []\n",
    "all_one_params = []\n",
    "all_one_stats  = []\n",
    "\n",
    "counter = 0\n",
    "start_time = time.time()\n",
    "for ind in indizes:\n",
    "    if ind % 1000 == 0: print('---- Index:', ind, '----')\n",
    "    target_params = samples_MAF[ind]\n",
    "    target = target_params\n",
    "    \n",
    "    if (target[24] > 0.9-np.sqrt(3) and target[24] < 1.3-np.sqrt(3)) and (target[25] > 1.75-np.sqrt(3) and target[25] < 2.18-np.sqrt(3)):\n",
    "        target_params = target_params * params_std + params_mean\n",
    "        out_target = pyloric_sim[0].gen_single(deepcopy(target_params), seed_sim=True, to_seed=1) # params.true_params gives the synaptic strengths #  165000\n",
    "        ss = summ_stats.calc([out_target])[0]\n",
    "        ss_diff = np.abs(summstats_experimental[:15] - ss[:15]) / exp_stds[:15]\n",
    "        if np.all(ss_diff < 0.1):\n",
    "            all_one_params.append(target_params)\n",
    "            all_one_stats.append(ss)\n",
    "            print('Found 0.1 std diff')\n",
    "\n",
    "np.savez('results/31D_pairs/all_similar_to_obs/sample_params_end.npz', params=all_one_params, summ_stats=all_one_stats)\n",
    "print('Overall time:  ', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for samples with similar activity but disparate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('results/31D_pairs/all_similar_to_obs/sample_params_start.npz')\n",
    "sample_params_start = npz['params']\n",
    "sample_stats_start  = npz['summ_stats']\n",
    "npz = np.load('results/31D_pairs/all_similar_to_obs/sample_params_end.npz')\n",
    "sample_params_end = npz['params']\n",
    "sample_stats_end  = npz['summ_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_s = (sample_params_start - params_mean) / params_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_baselines = 0\n",
    "number_baselines = len(sample_stats_start)\n",
    "number_comparisons = len(sample_stats_end)\n",
    "\n",
    "all_index1 = []\n",
    "all_index2 = []\n",
    "all_num_diff = []\n",
    "all_num_diff_membrane = []\n",
    "all_num_diff_syn = []\n",
    "\n",
    "margin = 0.1\n",
    "\n",
    "for baseline_num in range(start_baselines, start_baselines+number_baselines):\n",
    "    \n",
    "    baseline_sample = deepcopy(sample_stats_start[baseline_num])\n",
    "    baseline_params = deepcopy(sample_params_start[baseline_num])\n",
    "        \n",
    "    for compare_sample_num in range(number_comparisons):\n",
    "        current_sample = sample_stats_end[compare_sample_num]\n",
    "        current_params = sample_params_end[compare_sample_num]\n",
    "        \n",
    "        if seu.check_equality(baseline_sample, current_sample, margin=margin, stats_std=stats_std, mode='dataset'):\n",
    "            all_index1, all_index2 = seu.check_num_different_conds(baseline_params, current_params, all_index1, all_index2)\n",
    "outfile = 'results/31D_pairs/similar_to_each_other/sample_pair'\n",
    "np.savez_compressed(outfile, params1=all_index1, params2=all_index2)\n",
    "print('--- Finished successfully ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('results/31D_pairs/similar_to_each_other/sample_pair.npz')\n",
    "index1 = npz['params1']\n",
    "index2 = npz['params2']\n",
    "print(len(index1))\n",
    "params = netio.load_setup('train_31D_R1_BigPaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "#for pair_num in range(len(index1)):\n",
    "for pair_num in [2,3,6,17,21,24,27,28]:\n",
    "    print('Novel pair', pair_num)\n",
    "    params1 = index1[pair_num]\n",
    "    params2 = index2[pair_num]\n",
    "    \n",
    "    target_params = params1\n",
    "    out_target = pyloric_sim[0].gen_single(deepcopy(target_params), seed_sim=True, to_seed=418011) # params.true_params gives the synaptic strengths #  165000\n",
    "\n",
    "    fig = viz_samples_thesis.vis_sample(pyloric_sim[0], summ_stats, target_params, voltage_trace=out_target, test_idx=[0], case='high_p', hyperparams=params, scale_bar=False, vis_legend=False, offset_labels=1000, with_ss=False, time_len=165000, fontscale=1.2, linescale=1.2, legend=False, offset=20000,\n",
    "                                 mode='31D', mem_dimensions=[0,1,8,14,19,21], title='Sample along the path of high probability in Prinz format', date_today='190705_posterior_samples_experimental', multiplier_cond_shift=80, mode2='small', counter=0, save_fig=False)\n",
    "    plt.show()\n",
    "    \n",
    "    target_params = params2\n",
    "    out_target = pyloric_sim[0].gen_single(deepcopy(target_params), seed_sim=True, to_seed=418011) # params.true_params gives the synaptic strengths #  165000\n",
    "\n",
    "    fig = viz_samples_thesis.vis_sample(pyloric_sim[0], summ_stats, target_params, voltage_trace=out_target, test_idx=[0], case='high_p', hyperparams=params, scale_bar=False, vis_legend=False, offset_labels=1000, with_ss=False, time_len=165000, fontscale=1.2, linescale=1.2, legend=False, offset=20000,\n",
    "                                 mode='31D', mem_dimensions=[0,1,8,14,19,21], title='Sample along the path of high probability in Prinz format', date_today='190705_posterior_samples_experimental', multiplier_cond_shift=80, mode2='small', counter=0, save_fig=False)\n",
    "    plt.show()\n",
    "    \n",
    "    outfile = 'results/31D_pairs/similar_and_good/sample_pair_{}'.format(counter)\n",
    "    np.savez_compressed(outfile, params1=(params1-params_mean)/params_std, params2=(params2-params_mean)/params_std)\n",
    "    \n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ind2",
   "language": "python",
   "name": "ind2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
