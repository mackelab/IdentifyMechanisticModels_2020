{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference for Gabor-GLM with SNPE\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters\n",
    "\n",
    "- we fit a mixture-density network with convolutional layers to directly obtain posterior estimates from spike-triggered averages (STAs)\n",
    "- two-stage fitting procedure: \n",
    "    - a first round identifies the rough region in parameter space by fitting a Gaussian posterior approximation\n",
    "    - a second round identifies the exact posterior shape within that region by fitting an 8-component mixture of Gaussians. \n",
    "    \n",
    "- this notebook imports a custom CDELFI which does custom init of components for second round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    import os    \n",
    "    os.environ['THEANO_FLAGS'] = \"device=cuda0\"\n",
    "\n",
    "import theano\n",
    "theano.config.floatX='float32'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lasagne.nonlinearities as lnl\n",
    "import dill as pickle\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "from support_files.CDELFI import CDELFI\n",
    "import delfi.utils.io as io\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "from utils import get_maprf_prior_01, setup_sim, setup_sampler, \\\n",
    "get_data_o, quick_plot, contour_draws\n",
    "from model.gabor_rf import maprf as model\n",
    "from model.gabor_stats import maprfStats\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_hist_marginals(data, weights=None, lims=None, gt=None, upper=False, rasterized=False):\n",
    "    \"\"\"\n",
    "    Plots marginal histograms and pairwise scatter plots of a dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    n_bins = int(np.sqrt(data.shape[0]))\n",
    "\n",
    "    if data.ndim == 1:\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.hist(data, weights=weights, bins=n_bins, normed=True, rasterized=rasterized)\n",
    "        ax.set_ylim([0.0, ax.get_ylim()[1]])\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "        if lims is not None: ax.set_xlim(lims)\n",
    "        if gt is not None: ax.vlines(gt, 0, ax.get_ylim()[1], color='r')\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_dim = data.shape[1]\n",
    "        fig = plt.figure()\n",
    "\n",
    "        if weights is None:\n",
    "            col = 'k'\n",
    "            vmin, vmax = None, None\n",
    "        else:\n",
    "            col = weights\n",
    "            vmin, vmax = 0., np.max(weights)\n",
    "\n",
    "        if lims is not None:\n",
    "            lims = np.asarray(lims)\n",
    "            lims = np.tile(lims, [n_dim, 1]) if lims.ndim == 1 else lims\n",
    "\n",
    "        for i in range(n_dim):\n",
    "            for j in range(i, n_dim) if upper else range(i + 1):\n",
    "\n",
    "                ax = fig.add_subplot(n_dim, n_dim, i * n_dim + j + 1)\n",
    "\n",
    "                if i == j:\n",
    "                    ax.hist(data[:, i], weights=weights, bins=n_bins, normed=True, rasterized=rasterized)\n",
    "                    ax.set_ylim([0.0, ax.get_ylim()[1]])\n",
    "                    ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "                    if i < n_dim - 1 and not upper: ax.tick_params(axis='x', which='both', labelbottom=False)\n",
    "                    if lims is not None: ax.set_xlim(lims[i])\n",
    "                    if gt is not None: ax.vlines(gt[i], 0, ax.get_ylim()[1], color='r')\n",
    "\n",
    "                else:\n",
    "                    ax.scatter(data[:, j], data[:, i], c=col, s=3, marker='o', vmin=vmin, vmax=vmax, cmap='binary', edgecolors='none', rasterized=rasterized)\n",
    "                    if i < n_dim - 1: ax.tick_params(axis='x', which='both', labelbottom=False)\n",
    "                    if j > 0: ax.tick_params(axis='y', which='both', labelleft=False)\n",
    "                    if j == n_dim - 1: ax.tick_params(axis='y', which='both', labelright=True)\n",
    "                    if lims is not None:\n",
    "                        ax.set_xlim(lims[j])\n",
    "                        ax.set_ylim(lims[i])\n",
    "                    if gt is not None: ax.scatter(gt[j], gt[i], c='r', s=20, marker='o', edgecolors='none')\n",
    "\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation, models\n",
    "reload_obs_stats = False\n",
    "\n",
    "if reload_obs_stats:\n",
    "    gtd = np.load('results/SNPE/toycell_6/ground_truth_data.npy', allow_pickle=True)[()]\n",
    "    obs_stats = gtd['obs_stats']\n",
    "    sim_info = np.load('results/sim_info.npy', allow_pickle=True)[()]\n",
    "    d, params_ls = sim_info['d'], sim_info['params_ls']\n",
    "    p = get_maprf_prior_01(params_ls)\n",
    "    import delfi.generator as dg\n",
    "    g = dg.Default(model=None, prior=p[0], summary=None)\n",
    "else:\n",
    "    # result dirs\n",
    "    !mkdir -p results/\n",
    "    !mkdir -p results/SNPE/\n",
    "    !mkdir -p results/SNPE/toycell_6/\n",
    "\n",
    "    # training data and true parameters, data, statistics\n",
    "    idx_cell = 6 # load toy cell number 6 (cosine-shaped RF with 1Hz firing rate)\n",
    "    filename = 'results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "\n",
    "    g, prior, d = setup_sim(seed, path='')\n",
    "    obs_stats, pars_true = get_data_o(filename, g, seed)\n",
    "    rf = g.model.params_to_rf(pars_true)[0]\n",
    "\n",
    "    # plot ground-truth receptive field\n",
    "    plt.imshow(rf, interpolation='None')\n",
    "    plt.show()\n",
    "    obs_stats, obs_stats[0,-1] # summary statistics: (STA , spike count (over 5 minutes simulation) )\n",
    "\n",
    "    np.save('results/SNPE/toycell_6/ground_truth_data',\n",
    "            {'obs_stats' : obs_stats, 'pars_true' : pars_true, 'rf' : rf})\n",
    "\n",
    "    # visualize RFs defined by prior-drawn parameters theta\n",
    "    contour_draws(g.prior, g, obs_stats, d=d)\n",
    "    print(obs_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture: 9 layer network [5x conv, 3x fully conn., 1x MoG] \n",
    "\n",
    "filter_sizes=[3,3,3,3,2]   # 5 conv ReLU layers\n",
    "n_filters=(16,16,32,32,32) # 16 to 32 filters\n",
    "pool_sizes=[1,2,2,2,2]     # pooling layers\n",
    "n_hiddens=[50,50]          # 2 fully connected layers per MAF\n",
    "actfun=lnl.rectify         # using ReLU's for fully connected layers\n",
    "\n",
    "\n",
    "# N = 10k for first round\n",
    "\n",
    "n_train = 10000\n",
    "n_rounds = 2\n",
    "\n",
    "# number of Gaussian components for final-round posterior estimate\n",
    "\n",
    "# feature for CNN architectures: passing a value directly to the hidden layers (bypassing the conv layers).\n",
    "# In this case, we pass the number of spikes (single number) directly, which allows to normalize the STAs \n",
    "# and hence help out the conv layers. Without that extra input, we couldn't recover the RF gain anymore!\n",
    "n_inputs_hidden = 1\n",
    "\n",
    "# some learning-schedule parameters\n",
    "lr_decay = 0.999 # learning-rate decay over epochs\n",
    "epochs = 500     # number of epochs\n",
    "minibatch=100    # minibatch-size for stochastic gradient descent\n",
    "\n",
    "svi=False        # whether to regularize the network weight. Large N should make this do very little anyways\n",
    "reg_lambda=0.0   # regularization strength (not used if svi=False)\n",
    "\n",
    "pilot_samples=1000 # z-scoring only applies to extra inputs (here: firing rate) directly fed to fully connected layers\n",
    "\n",
    "prior_norm = False  # normalizes prior scales to mean zero and unit variances. \n",
    "                   # Helpful if parameter have vastly different scales.\n",
    "init_norm = False  # normalizes network intitialization. Not yet support for conv- and ReLU- layers\n",
    "\n",
    "rank = None   # no rank constraint on covariance matrices of posterior\n",
    "\n",
    "\n",
    "n_mades = 5\n",
    "act_fun = 'tanh'\n",
    "mode = 'random'\n",
    "\n",
    "rng = np.random\n",
    "rng.seed(seed)\n",
    "\n",
    "batch_norm= False\n",
    "val_frac = 0.02\n",
    "\n",
    "assert (n_train * val_frac) % minibatch == 0 # cannot deal with incomplete minibatches right now....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_stats[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inf = infer.APT(\n",
    "    generator=g, \n",
    "    obs=obs_stats, \n",
    "    prior_norm=prior_norm,                                # PRIOR NORMALIZATION OFF\n",
    "    pilot_samples=pilot_samples,\n",
    "    seed=seed, \n",
    "    svi=False,\n",
    "    \n",
    "    n_hiddens=n_hiddens, \n",
    "    n_filters=n_filters, \n",
    "\n",
    "    density='maf',\n",
    "    n_mades=n_mades, \n",
    "    maf_actfun=act_fun,\n",
    "    maf_mode=mode, \n",
    "    batch_norm=batch_norm,\n",
    "    \n",
    "    \n",
    "    n_inputs = d*d,\n",
    "    input_shape = (1,d,d), \n",
    "    n_bypass=1,\n",
    "    filter_sizes=filter_sizes, \n",
    "    pool_sizes=pool_sizes, \n",
    "    actfun=actfun,\n",
    "    verbose=True)\n",
    "\n",
    "inf.network.aps[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameter numbers per layer (just weights, not biases)\n",
    "def get_shape(i):\n",
    "    return inf.network.aps[i].get_value().shape\n",
    "print([get_shape(i) for i in range(1,17,2)])\n",
    "print([np.prod(get_shape(i)) for i in range(1,17,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run SNPE-C\n",
    "print('fitting model with SNPC-C')\n",
    "log, trn_data, posteriors = inf.run(\n",
    "\n",
    "                    n_train=n_train,\n",
    "                    epochs=epochs, \n",
    "                    proposal='atomic',\n",
    "    \n",
    "                    n_atoms = minibatch - 1, \n",
    "                    moo='resample', \n",
    "    \n",
    "                    n_rounds=n_rounds,\n",
    "                    train_on_all=False,\n",
    "                    minibatch=minibatch,\n",
    "                    val_frac=val_frac,\n",
    "                    silent_fail=False, \n",
    "                    verbose=True, \n",
    "                    print_each_epoch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(len(posteriors)):\n",
    "    \n",
    "    posterior = posteriors[r]\n",
    "\n",
    "    post_draws = posterior.gen(1000)\n",
    "\n",
    "    plot_prior = dd.TransformedNormal(m=g.prior.m, S = g.prior.S,\n",
    "                                flags=[0,0,2,1,2,1,1,2,2],\n",
    "                                lower=[0,0,0,0,0,0,0,-1,-1], upper=[0,0,np.pi,0,2*np.pi,0,0,1,1]) \n",
    "\n",
    "    post_draws_trans = plot_prior._f(post_draws)\n",
    "\n",
    "\n",
    "    fig = plot_hist_marginals(data=post_draws_trans, weights=None, \n",
    "                              lims=[[-1.5,1.5], [-1.1,1.1], [0,np.pi], [0, 2.5], [0,2*np.pi], [0,2], [0,4], [-1,1], [-1,1]], \n",
    "                              gt=None, upper=True, rasterized=False)\n",
    "    fig.set_figwidth(16)\n",
    "    fig.set_figheight(16)\n",
    "    fig.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot posteriors in original space (back-transformed)\n",
    "fitting Gaussians on log-transformed (frequency, ratio, width) and logit-transformed (phase, angle , location) parameters gives log- resp. logit-Normal marginals on original parameters. The 9-dimenensional joint distribution of all parameters can be transformed analytically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prior = dd.TransformedNormal(m=g.prior.m, S = g.prior.S,\n",
    "                            flags=[0,0,2,1,2,1,1,2,2],\n",
    "                            lower=[0,0,0,0,0,0,0,-1,-1], upper=[0,0,np.pi,0,2*np.pi,0,0,1,1]) \n",
    "\n",
    "plot_post = dd.mixture.TransformedGaussianMixture.MoTG(\n",
    "                            ms= [posterior.xs[i].m for i in range(posterior.n_components)], \n",
    "                            Ss =[posterior.xs[i].S for i in range(posterior.n_components)],\n",
    "                            a = posterior.a, \n",
    "                            flags=[0,0,2,1,2,1,1,2,2],\n",
    "                            lower=[0,0,0,0,0,0,0,-1,-1], upper=[0,0,np.pi,0,2*np.pi,0,0,1,1]) \n",
    "\n",
    "lims = np.array([[-2, -1.5, .001, 0,       .001, 0, 0, -.999, -.999], \n",
    "                 [ 2,  1.5, .999*np.pi, 3, 1.999*np.pi, 3, 3, .999,   .999]]).T\n",
    "\n",
    "fig, _ = plot_pdf(plot_post, pdf2=plot_prior, lims=lims, gt=plot_post._f(pars_true.reshape(1,-1)).reshape(-1), \n",
    "                  figsize=(16,16), resolution=100,\n",
    "                  labels_params=['bias', 'gain', 'logit phase', 'log freq', 'logit angle', 'log ratio', 'log width', 'xo', 'yo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show contours of posterior draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvls=[0.5, 0.5]\n",
    "p = posterior\n",
    "n_draws = 10 \n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(obs_stats[0,:-1].reshape(d,d), interpolation='None', cmap='gray')\n",
    "for i in range(n_draws):\n",
    "    rfm = g.model.params_to_rf(p.gen().reshape(-1))[0]\n",
    "    plt.contour(rfm, levels=[lvls[0]*rfm.min(), lvls[1]*rfm.max()])\n",
    "    #print(rfm.min(), rfm.max())\n",
    "    #plt.hold(True)\n",
    "plt.title('RF posterior draws')\n",
    "\n",
    "rfm = g.model.params_to_rf(pars_true.reshape(-1))[0]\n",
    "plt.contour(rfm, levels=[lvls[0]*rfm.min(), lvls[1]*rfm.max()], colors='r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_ = 2\n",
    "filename1 = 'results/SNPE/toycell_6/maprf_100k_prior01_run_1_round' + str(round_) + '_param9_nosvi_CDELFI.pkl'\n",
    "filename2 = 'results/SNPE/toycell_6/maprf_100k_prior01_run_1_round' + str(round_) + '_param9_nosvi_CDELFI_res.pkl'\n",
    "filename4 = 'results/SNPE/toycell_6/maprf_100k_prior01_run_1_round' + str(round_) + '_param9_nosvi_CDELFI_net_only.pkl'\n",
    "\n",
    "io.save_pkl((log2, trn_data2, posteriors2),filename1)\n",
    "net = inf.network\n",
    "data = {'network.spec_dict' : net.spec_dict, \n",
    "        'network.params_dict' : net.params_dict }\n",
    "io.save_pkl(data, filename4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key results for figure 3 in paper\n",
    "np.save('results/SNPE/toycell_6/maprf_100k_prior01_run_1_round' + str(round_) + '_param9_nosvi_CDELFI_posterior',\n",
    "        {'posterior' : posteriors2[-1],\n",
    "         'proposal' : inf.generator.proposal, \n",
    "         'prior' : inf.generator.prior})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_=2\n",
    "p=np.load('results/SNPE/toycell_6/maprf_100k_prior01_run_1_round' + str(round_) + '_param9_nosvi_CDELFI_posterior.npy', allow_pickle=True)[()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
