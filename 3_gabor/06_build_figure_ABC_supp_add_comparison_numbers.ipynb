{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference for Gabor-GLM with ABC methods\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters\n",
    "\n",
    "- we run a classical likelihood-free inference algorithm (SMC-ABC) on the Gabor-GLM simulator\n",
    "- like SNPE, SMC-ABC iteratively refines a posterior estimate across multiple rounds\n",
    "- within each rounds, SMC-ABC runs a rejection-sampling scheme that rejects parameters based on a distance measure $d(x,x_o)$.\n",
    "\n",
    "\n",
    "- the design of this distance measure $d$ can be tricky and requires good summary statistics.\n",
    "- here we use a standard approach: squared error on (normalized) summary statistics, $d(x,x_o) = || (x-x_o) \\ / \\ std ||_2$.\n",
    "- this standard approach does not work well here, since the summary statistics in this case include a $1641$-dimensional spike-triggered average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "import theano\n",
    "theano.config.floatX='float64'\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "#from delfi.utils.viz import plot_pdf\n",
    "\n",
    "from model.gabor_rf import maprf as model\n",
    "from model.gabor_stats import maprfStats\n",
    "from utils import setup_sim, get_data_o, setup_sampler, quick_plot, contour_draws\n",
    "\n",
    "import sys; sys.path.append('../')\n",
    "from common import col, svg, plot_pdf\n",
    "\n",
    "from support_files.run_abc import run_smc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42    # seed for generation of xo for selected cell. MCMC currently not seeded !\n",
    "\n",
    "idx_cell = 6 # load toy cell number i = idx_cell\n",
    "\n",
    "maxsim = int(1e6)\n",
    "n_particles= int(1e3)\n",
    "\n",
    "savefile = 'results/SMC/toycell_' + str(idx_cell) + '/maprf_SMC_prior01_run_1_'+ str(n_particles) + 'particles_param9'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load cell, generate xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, prior, d = setup_sim(seed, path='')\n",
    "\n",
    "filename = 'results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "params_dict_true = np.load(filename, allow_pickle=True)[()]\n",
    "params_dict_true['kernel']['t'] = {'value' : 1.}\n",
    "\n",
    "m = g.model\n",
    "m.params_dict = params_dict_true.copy()\n",
    "m.rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "pars_true, obs = m.read_params_buffer(), m.gen_single()\n",
    "obs_stats = g.summary.calc([obs])\n",
    "\n",
    "# plot ground-truth receptive field\n",
    "rf = g.model.params_to_rf(pars_true)[0]\n",
    "plt.imshow(np.hstack((obs_stats[0,:-1].reshape(d,d), rf)), interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "print('spike count', obs_stats[0,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_sampler\n",
    "from maprf.utils import empty\n",
    "from theano import In\n",
    "import theano.tensor as tt\n",
    "import scipy.stats as st\n",
    "\n",
    "g, prior_dict, d = setup_sim(seed, path='')\n",
    "params_dict_true['kernel']['t'] = {'value' : 1. }\n",
    "prior = g.prior\n",
    "\n",
    "inference, data = setup_sampler(prior_dict, obs, d, g, params_dict=params_dict_true, \n",
    "                          fix_position=False, parametrization='logit_φ')\n",
    "\n",
    "# Gamma prior parameters\n",
    "alpha = inference.priors['glm']['bias']['alpha']\n",
    "beta = inference.priors['glm']['bias']['beta']\n",
    "\n",
    "# could try to grad the following also from the existing graph?\n",
    "x = tt.as_tensor_variable(data[0], 'x')\n",
    "y = tt.as_tensor_variable(data[1], 'y')\n",
    "η = inference.filter(x, inference.updates)\n",
    "\n",
    "α = theano.function([], tt.sum(y) + alpha,\n",
    "                    on_unused_input='warn',\n",
    "                    allow_input_downcast=True)\n",
    "\n",
    "# get binsize without adding it to self.inputs\n",
    "Δ = theano.shared(empty(inference.emt.binsize.ndim), inference.emt.binsize.name)\n",
    "in_Δ = In(inference.emt.binsize, value=Δ.container, implicit=False)\n",
    "Δ.set_value(m.dt)\n",
    "\n",
    "i = list(inference.inputs.values()) + [in_Δ]\n",
    "β = theano.function(i, inference.emt.binsize * tt.sum(tt.exp(η)) + beta,\n",
    "                    on_unused_input='warn', allow_input_downcast=True)\n",
    "\n",
    "def loglikelihood(params):\n",
    "\n",
    "    # use g.model to translate between SNPE/SMC parametrization and mapRF parametrization\n",
    "    g.model._set_pars_dict(params)\n",
    "    params_dict = g.model.params_dict\n",
    "\n",
    "    # update inference object with translated parameters\n",
    "    loglik = inference.loglik\n",
    "    fix_position = False\n",
    "    if fix_position:\n",
    "        loglik['logit_xo'] = 0.\n",
    "        loglik['logit_yo'] = 0.\n",
    "    else:\n",
    "        kl =  params_dict['kernel']['l']\n",
    "        loglik['logit_xo'] = np.log( (1+kl['xo']) / (  1. - kl['xo']))\n",
    "        loglik['logit_yo'] = np.log( (1+kl['yo']) / (  1. - kl['yo']))\n",
    "    loglik['kt'] = params_dict['kernel']['t']['value']\n",
    "    ks = params_dict['kernel']['s']\n",
    "    loglik['log_γ'] = np.log(ks['ratio'])\n",
    "    loglik['log_b'] = np.log(ks['width'])\n",
    "    loglik['log_A']   = np.log(ks['gain'])\n",
    "    loglik['logit_φ'] =  np.log(ks['phase'] / (  np.pi - ks['phase']))\n",
    "    loglik['log_f'] = np.log(ks['freq'])\n",
    "    loglik['logit_θ'] = np.log(ks['angle'] / (2*np.pi - ks['angle']))\n",
    "    \n",
    "    # inference.loglik is integrated over biases! \n",
    "    # If all 9 parameters are divided into 8 params for the spatial kernel params_ks and \n",
    "    # one bias parameter, then the probabilities work out as \n",
    "    # p(x|params_ks, bias) = p(bias|x, params_ks) * p(x | params_ks) / p(bias|params_ks)\n",
    "    ll = inference.loglik() # = p(x | params_ks)\n",
    "    ll += np.log(st.gamma.pdf(np.exp(params_dict['glm']['bias']), \n",
    "                              a=α(), scale=1./β(), loc=0)) # = p(bias|x, params_ks) \n",
    "    ll -= prior.eval(np.exp(params_dict['glm']['bias']), ii=0, log=True) # = p(bias|params_ks)\n",
    "                     \n",
    "    return ll\n",
    "\n",
    "def logjointdensities(params):\n",
    "    \n",
    "    return loglikelihood(params) + prior.eval(params, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load SMC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normed_summary(): # definition just necessary for loading SMC results below\n",
    "    def calc(self, y):\n",
    "        x = g.summary.calc(y)\n",
    "        return (x-stats_mean)/stats_std\n",
    "\n",
    "res = np.load('results/SMC/toycell_6/maprf_SMC_prior01_run_1_1000particles_param9.npy',\n",
    "    allow_pickle=True)[()]\n",
    "\n",
    "for k,v in res.items():\n",
    "    globals()[k] = v\n",
    "    \n",
    "params_SMC = res['all_ps'][-1]\n",
    "lls_SMC = np.zeros(params_SMC.shape[0])\n",
    "ljs_SMC = np.zeros(params_SMC.shape[0])\n",
    "for i in range(params_SMC.shape[0]):\n",
    "    lls_SMC[i] = loglikelihood(params_SMC[i,:])\n",
    "    ljs_SMC[i] = logjointdensities(params_SMC[i,:])\n",
    "\n",
    "        \n",
    "plt.hist(lls_SMC, normed=True)\n",
    "plt.plot(loglikelihood(pars_true)*np.ones(2), [0,0.008], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, _, d = setup_sim(seed, path='')\n",
    "corrs_SMC = np.zeros(params_SMC.shape[0])\n",
    "for i in range(params_SMC.shape[0]):\n",
    "    out = g.model.gen_single(params_SMC[i])\n",
    "    corrs_SMC[i] = np.corrcoef(obs['data'], out['data'])[0,1]\n",
    "\n",
    "plt.hist(corrs_SMC, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load SNPE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load('results/SNPE/toycell_6/maprf_100k_prior01_run_1_round2_param9_nosvi_CDELFI_posterior.npy',\n",
    "              allow_pickle=True)[()]\n",
    "posterior, proposal, prior = tmp['posterior'], tmp['proposal'], tmp['prior']\n",
    "\n",
    "params_SNPE = posterior.gen(1000)\n",
    "\n",
    "lls_SNPE = np.zeros(params_SNPE.shape[0])\n",
    "ljs_SNPE = np.zeros(params_SNPE.shape[0])\n",
    "for i in range(params_SNPE.shape[0]):\n",
    "    lls_SNPE[i] = loglikelihood(params_SNPE[i,:])\n",
    "    ljs_SNPE[i] = logjointdensities(params_SNPE[i,:])\n",
    "plt.hist(lls_SNPE, normed=True)\n",
    "plt.plot(loglikelihood(pars_true)*np.ones(2), [0,0.008], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, _, d = setup_sim(seed, path='')\n",
    "corrs_SNPE = np.zeros(params_SNPE.shape[0])\n",
    "for i in range(params_SNPE.shape[0]):\n",
    "    out = g.model.gen_single(params_SNPE[i])\n",
    "    corrs_SNPE[i] = np.corrcoef(obs['data'], out['data'])[0,1]\n",
    "\n",
    "plt.hist(corrs_SNPE, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf(posterior, lims=[-4,4], figsize=(16,16));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load MCMC resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cell = 6 # load toy cell number 6 (cosine-shaped RF with 1Hz firing rate)\n",
    "\n",
    "fix_position=True         # fixues RF position during sampling to (0,0)\n",
    "parametrization='logit_φ' # chosen parameterization of Gabor (affects priors !) \n",
    "\n",
    "n_samples = 1000000  # number of MCMC samples\n",
    "\n",
    "savefile = 'results/MCMC/toycell_' + str(idx_cell) + '/maprf_MCMC_prior01_run_1_'+ str(n_samples)+'samples_param9_5min'\n",
    "\n",
    "T = np.load(savefile+'.npy',allow_pickle=True)[()]['T']\n",
    "samples_MCMC = np.hstack([np.atleast_2d(T[key].T).T for key in ['bias', 'gain', 'logit_φ', 'log_f','logit_θ','log_γ','log_b', 'logit_xo', 'logit_yo']])\n",
    "samples_MCMC = samples_MCMC[-500000:-1:500, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in res.items():\n",
    "    globals()[k] = v\n",
    "    \n",
    "lls_MCMC = np.zeros(samples_MCMC.shape[0])\n",
    "ljs_MCMC = np.zeros(samples_MCMC.shape[0])\n",
    "for i in range(samples_MCMC.shape[0]):\n",
    "    lls_MCMC[i] = loglikelihood(samples_MCMC[i,:])\n",
    "    ljs_MCMC[i] = logjointdensities(samples_MCMC[i,:])\n",
    "\n",
    "\n",
    "plt.hist(lls_MCMC, normed=True)\n",
    "plt.plot(loglikelihood(pars_true)*np.ones(2), [0,0.008], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, _, d = setup_sim(seed, path='')\n",
    "corrs_MCMC = np.zeros(samples_MCMC.shape[0])\n",
    "for i in range(samples_MCMC.shape[0]):\n",
    "    out = g.model.gen_single(samples_MCMC[i])\n",
    "    corrs_MCMC[i] = np.corrcoef(obs['data'], out['data'])[0,1]\n",
    "\n",
    "plt.hist(corrs_MCMC, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare with prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_prior = prior.gen(1000)\n",
    "\n",
    "lls_prior = np.zeros(params_prior.shape[0])\n",
    "ljs_prior = np.zeros(params_prior.shape[0])\n",
    "for i in range(params_SNPE.shape[0]):\n",
    "    lls_prior[i] = loglikelihood(params_prior[i,:])\n",
    "    ljs_prior[i] = logjointdensities(params_prior[i,:])\n",
    "    \n",
    "lls_prior[lls_prior==-np.inf] = -10000 # lazy numerics\n",
    "ljs_prior[lls_prior==-np.inf] = -10000 # make sure to focus evaluation on area where numerics are stable\n",
    "\n",
    "plt.hist(lls_prior, normed=True)\n",
    "plt.plot(loglikelihood(pars_true)*np.ones(2), [0,0.008], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, _, d = setup_sim(seed, path='')\n",
    "corrs_prior = np.zeros(params_prior.shape[0])\n",
    "for i in range(params_prior.shape[0]):\n",
    "    out = g.model.gen_single(params_prior[i])\n",
    "    corrs_prior[i] = np.corrcoef(obs['data'], out['data'])[0,1]\n",
    "\n",
    "plt.hist(corrs_prior, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: distribution of r(x, xo) for x ~ p(x|theta_true) - same order of magnitude?\n",
    "corrs_px = np.zeros(10000)\n",
    "for i in range(10000):\n",
    "    obs1=g.model.gen_single(pars_true)\n",
    "\n",
    "    corrs_px[i] = np.corrcoef(obs1['data'], obs['data'])[0,1]\n",
    "    \n",
    "plt.hist(corrs_px)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(corrs_px), np.std(corrs_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(corrs_prior, normed=True)#, bins=np.linspace(-3300, -2750, 30), label='prior')\n",
    "plt.hist(corrs_SMC,   normed=True)#, bins=np.linspace(-3300, -2750, 30), label='SMC')\n",
    "plt.hist(corrs_SNPE,  normed=True)#, bins=np.linspace(-3300, -2750, 30), label='SNPE')\n",
    "plt.xlabel('correlations')\n",
    "plt.ylabel('density')\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(lls_prior, normed=True, bins=np.linspace(-3300, -2750, 30), label='prior')\n",
    "plt.hist(lls_SMC,   normed=True, bins=np.linspace(-3300, -2750, 30), label='SMC')\n",
    "plt.hist(lls_SNPE,  normed=True, bins=np.linspace(-3300, -2750, 30), label='SNPE')\n",
    "plt.plot(loglikelihood(pars_true)*np.ones(2), [0,0.07], 'k', linewidth=2, label='gt')\n",
    "plt.xlabel('log-likelihoods')\n",
    "plt.ylabel('density')\n",
    "plt.yticks([])\n",
    "plt.xticks([-3100, -3000, -2900, -2800])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 11\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "\n",
    "plt.hist(np.vstack((corrs_prior, corrs_SMC, corrs_SNPE, corrs_MCMC)).T, normed=True, \n",
    "         bins=np.linspace(-0.035, 0.05, 20), \n",
    "         label=['prior', 'SMC-ABC', 'SNPE', 'MCMC'],\n",
    "         color=[(0.55,0.,0.), col['SMC'], col['SNPE'], col['MCMC']],\n",
    "         histtype='bar',\n",
    "         rwidth=1.0)\n",
    "plt.xlabel('correlations', fontsize=fontsize)\n",
    "plt.ylabel('density', fontsize=fontsize)\n",
    "plt.yticks([])\n",
    "plt.xticks([-0.02, 0.0, 0.02, 0.04])\n",
    "plt.legend(fontsize=fontsize, frameon=False)\n",
    "\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(logjointdensities(pars_true)*np.ones(2), [0,950], 'g', linewidth=1, label='ground-truth param.')\n",
    "\n",
    "plt.hist(np.vstack((ljs_prior, ljs_SMC, ljs_SNPE, ljs_MCMC)).T, #normed=True, \n",
    "         bins=np.linspace(-3150, -2750, 40), \n",
    "         label=['prior', 'SMC-ABC', 'SNPE', 'MCMC'],\n",
    "         color=[(0.55,0.,0.), col['SMC'], col['SNPE'], col['MCMC']],\n",
    "         histtype='bar',\n",
    "         rwidth=1.0)\n",
    "\n",
    "plt.xlabel('log joint densities ' + r'$p(xo, \\theta)$', fontsize=fontsize)\n",
    "plt.ylabel('density', fontsize=fontsize)\n",
    "plt.yticks([])\n",
    "plt.xticks([-3100, -3000, -2900, -2800])\n",
    "plt.legend(fontsize=fontsize, frameon=False)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig(\"fig/fig3_gabor_supp_smc_abc_comps.svg\")\n",
    "plt.savefig(\"fig/fig3_gabor_supp_smc_abc_comps.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.boxplot(x=(ljs_prior, ljs_SMC, ljs_SNPE), labels=['prior', 'SMC', 'SNPE'])\n",
    "plt.ylabel('log joint densities')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_prior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_true = g.model.params_to_rf(pars_true)[0]\n",
    "\n",
    "rfcs_MCMC = np.zeros(samples_MCMC.shape[0])\n",
    "for i in range(samples_MCMC.shape[0]):\n",
    "    rf = g.model.params_to_rf(samples_MCMC[i])[0]\n",
    "    rfcs_MCMC[i] = np.corrcoef(rf_true.flatten(), rf.flatten())[0,1]\n",
    "    \n",
    "plt.hist(rfcs_MCMC, normed=True)\n",
    "plt.show()\n",
    "\n",
    "rfcs_SMC = np.zeros(params_SMC.shape[0])\n",
    "for i in range(params_SMC.shape[0]):\n",
    "    rf = g.model.params_to_rf(params_SMC[i])[0]\n",
    "    rfcs_SMC[i] = np.corrcoef(rf_true.flatten(), rf.flatten())[0,1]\n",
    "    \n",
    "plt.hist(rfcs_SMC, normed=True)\n",
    "plt.show()\n",
    "\n",
    "rfcs_SNPE = np.zeros(params_SNPE.shape[0])\n",
    "for i in range(params_SNPE.shape[0]):\n",
    "    rf = g.model.params_to_rf(params_SNPE[i])[0]\n",
    "    rfcs_SNPE[i] = np.corrcoef(rf_true.flatten(), rf.flatten())[0,1]\n",
    "    \n",
    "plt.hist(rfcs_SNPE, normed=True)\n",
    "plt.show()\n",
    "\n",
    "rfcs_prior = np.zeros(params_prior.shape[0])\n",
    "for i in range(params_prior.shape[0]):\n",
    "    rf = g.model.params_to_rf(params_prior[i])[0]\n",
    "    rfcs_prior[i] = np.corrcoef(rf_true.flatten(), rf.flatten())[0,1]\n",
    "    \n",
    "plt.hist(rfcs_prior, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 9\n",
    "fig_inches = (4,4)\n",
    "\n",
    "with mpl.rc_context(fname='../.matplotlibrc'):\n",
    "    fig = plt.figure(figsize=fig_inches)\n",
    "\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    plt.hist(rfcs_SMC, normed=True, \n",
    "             bins=np.linspace(-0.5, 1, 30), \n",
    "             label=['SMC-ABC'],\n",
    "             color=[col['SMC']],\n",
    "             histtype='bar',\n",
    "             rwidth=1.0)\n",
    "    plt.hist(rfcs_SNPE, normed=True, \n",
    "             bins=np.linspace(-0.5, 1, 30), \n",
    "             label=['SNPE'],\n",
    "             color=[col['SNPE']],\n",
    "             histtype='bar',\n",
    "             rwidth=1.0)\n",
    "    plt.hist(np.vstack((rfcs_prior, rfcs_MCMC)).T, normed=True, \n",
    "             bins=np.linspace(-0.5, 1, 30), \n",
    "             label=['prior', 'MCMC'],\n",
    "             color=[(0.55,0.,0.), col['MCMC']],\n",
    "             histtype='step',\n",
    "             rwidth=1.0,\n",
    "             lw=2)\n",
    "    plt.xlabel('correlations', fontsize=fontsize)\n",
    "    plt.ylabel('density', fontsize=fontsize)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([-0.5, 0.0, 0.5, 1.])\n",
    "    plt.legend(fontsize=fontsize, frameon=False, loc=2)\n",
    "\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    fig.savefig('fig/fig3_gabor_supp_smc_abc_comps.svg', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=11\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "plt.bar(x=np.arange(4),\n",
    "    height=[rfcs_prior.mean(), rfcs_SMC.mean(), rfcs_SNPE.mean(), rfcs_MCMC.mean()],\n",
    "         tick_label=['prior', 'SMC-ABC', 'SNPE', 'MCMC'],\n",
    "         color=[(0.55,0.,0.), col['SMC'], col['SNPE'], col['MCMC']])\n",
    "for i,rfcs in enumerate([rfcs_prior, rfcs_SMC, rfcs_SNPE, rfcs_MCMC]):\n",
    "    plt.plot(\n",
    "        (i)*np.ones(2), \n",
    "        rfcs.std()*np.array([-1,1]) + rfcs.mean(),\n",
    "        color=(0.4,0.4,0.4)\n",
    "    )\n",
    "plt.legend(fontsize=fontsize, frameon=False, loc=2)\n",
    "plt.plot([-0.5, 3.5], [1., 1.], 'k--')\n",
    "#plt.ylabel(r'$\\left< \\rho\\left( \\ RF, \\ \\hat{RF}\\ \\right) \\right>$', fontsize=fontsize)\n",
    "plt.ylabel('correlation', fontsize=fontsize)\n",
    "plt.yticks([0, 0.5, 1.], fontsize=fontsize)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig(\"fig/fig3_gabor_supp_smc_abc_comps_inset.svg\", bbox_inches='tight', frameon=False, transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
